{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from AdaBins.models.unet_adaptive_bins import UnetAdaptiveBins\n",
    "from AdaBins import model_io\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams['figure.dpi'] = 150\n",
    "\n",
    "MIN_DEPTH = 1e-3\n",
    "MAX_DEPTH_KITTI = 80\n",
    "\n",
    "N_BINS = 256\n",
    "\n",
    "model = UnetAdaptiveBins.build(n_bins=N_BINS, min_val=MIN_DEPTH, max_val=MAX_DEPTH_KITTI)\n",
    "\n",
    "\n",
    "pretrained_path = \"AdaBins/AdaBins_kitti.pt\"\n",
    "\n",
    "model, _, _ = model_io.load_checkpoint(pretrained_path, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "base_path = None # TODO Change to config file data read\n",
    "im_files = os.listdir(base_path+\"/image_2\")\n",
    "i = 20\n",
    "\n",
    "test_im = plt.imread(os.path.join(base_path,\"image_2\", im_files[i]))\n",
    "plt.imshow(test_im)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "test_im = plt.imread(os.path.join(base_path,\"semantic\", im_files[i]))\n",
    "\n",
    "test_im = (test_im*200).astype(int)\n",
    "\n",
    "hist, x = np.histogram(test_im)\n",
    "\n",
    "\n",
    "print(\"Test im max: \", test_im.max())\n",
    "print(\"Hist: \", hist.shape)\n",
    "print(\"X shape: \", x.shape)\n",
    "plt.bar(x[:-1], hist)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "test_im = np.where(test_im==18, 1, 0)\n",
    "\n",
    "print(test_im.sum())\n",
    "plt.imshow(test_im)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_im = plt.imread(os.path.join(base_path,\"image_2\", im_files[i]))\n",
    "mean = torch.load(\"normalization_cache/rgb_mean.pth\").unsqueeze(-1).unsqueeze(-1)\n",
    "sigma = torch.load(\"normalization_cache/rgb_std.pth\").unsqueeze(-1).unsqueeze(-1)\n",
    "\n",
    "rgb_tensor = torch.tensor(test_im).permute(2, 0, 1)\n",
    "#rgb_tensor = (rgb_tensor-mean)/sigma\n",
    "rgb_tensor = rgb_tensor.to(\"cuda\").unsqueeze(0)\n",
    "model = model.to(\"cuda\").eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    bin_edges, predicted_depth = model(rgb_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.transforms import Resize\n",
    "resize = Resize((375, 1242))\n",
    "predicted_depth = resize(predicted_depth)\n",
    "print(predicted_depth.shape)\n",
    "plt.imshow(predicted_depth.squeeze().cpu().detach().numpy())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "depth = resize(predicted_depth).squeeze().cpu().numpy()\n",
    "print(depth.shape)\n",
    "test_im = (200*plt.imread(os.path.join(base_path,\"semantic\", im_files[i]))).astype(int)\n",
    "\n",
    "fused_depth = np.where(test_im==18, MAX_DEPTH_KITTI, depth)\n",
    "plt.imshow(fused_depth)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fused_tensor = torch.tensor(fused_depth).unsqueeze(0).unsqueeze(0)\n",
    "print(fused_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "class SILogLoss(nn.Module):  # Main loss function used in AdaBins paper\n",
    "    def __init__(self):\n",
    "        super(SILogLoss, self).__init__()\n",
    "        self.name = 'SILog'\n",
    "\n",
    "    def forward(self, input, target, mask=None, interpolate=True):\n",
    "        if interpolate:\n",
    "            input = nn.functional.interpolate(input, target.shape[-2:], mode='bilinear', align_corners=True)\n",
    "\n",
    "        if mask is not None:\n",
    "            input = input[mask]\n",
    "            target = target[mask]\n",
    "        g = torch.log(input) - torch.log(target)\n",
    "        # n, c, h, w = g.shape\n",
    "        # norm = 1/(h*w)\n",
    "        # Dg = norm * torch.sum(g**2) - (0.85/(norm**2)) * (torch.sum(g))**2\n",
    "\n",
    "        Dg = torch.var(g) + 0.15 * torch.pow(torch.mean(g), 2)\n",
    "        return 10 * torch.sqrt(Dg)\n",
    "\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-5)\n",
    "model = model.train().to(\"cuda\")\n",
    "\n",
    "criterion_ueff = SILogLoss()\n",
    "\n",
    "img = torch.tensor(plt.imread(os.path.join(base_path,\"image_2\", im_files[i]))).permute(2, 0, 1).unsqueeze(0).to(\"cuda\")\n",
    "print(img.shape)\n",
    "fused_tensor = fused_tensor.to(\"cuda\")\n",
    "\n",
    "for i in range(100):\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    bin_edges, pred = model(img)\n",
    "\n",
    "    mask = fused_tensor > MIN_DEPTH\n",
    "    l_dense = criterion_ueff(pred, fused_tensor, mask=mask.to(torch.bool), interpolate=True)\n",
    "\n",
    "    l_dense.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    print(l_dense.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_im = plt.imread(os.path.join(base_path,\"image_2\", im_files[i]))\n",
    "rgb_tensor = torch.tensor(test_im).permute(2, 0, 1)\n",
    "\n",
    "rgb_tensor = rgb_tensor.to(\"cuda\").unsqueeze(0)\n",
    "model = model.to(\"cuda\").eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    bin_edges, predicted_depth = model(rgb_tensor)\n",
    "\n",
    "\n",
    "resize = Resize((375, 1242))\n",
    "\n",
    "print(resize(predicted_depth).shape)\n",
    "plt.imshow(resize(predicted_depth).squeeze().cpu().detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from localization.localization_dataset import KittiUnetDataset\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams['figure.dpi'] = 150\n",
    "\n",
    "DATA_PATH = None # TODO Change to config file data read\n",
    "dataset = KittiUnetDataset(data_path=DATA_PATH, sequence=\"00\")\n",
    "im_true, im_rand, _, _ = dataset[10]\n",
    "\n",
    "def convert(im):\n",
    "    return im.squeeze().permute(1, 2, 0).byte().cpu().numpy()\n",
    "\n",
    "def imshow_torch(im):\n",
    "    im = convert(im)\n",
    "    plt.imshow(im)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "imshow_torch(im_true)\n",
    "imshow_torch(im_rand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from localization.localization import MappingUnet\n",
    "from helpers import log\n",
    "from localization.localization_dataset import KittiLocalizationDataset, KittiUnetDataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from localization.localization_losses import VAE_loss\n",
    "from helpers import BetaScheduler\n",
    "from torch.nn import functional as F\n",
    "\n",
    "\n",
    "DEVICE = \"cuda\"\n",
    "DATA_PATH = None # TODO Change to config file data read\n",
    "dataset = KittiLocalizationDataset(data_path=DATA_PATH, sequence=\"00\", simplify=True, simplification_rate=5)\n",
    "#dataset = KittiUnetDataset(data_path=DATA_PATH, sequence=\"00\")\n",
    "\n",
    "rgb_mean = torch.load(\"normalization_cache/rgb_mean.pth\").unsqueeze(0).unsqueeze(-1).unsqueeze(-1).to(DEVICE)\n",
    "rgb_sigma = torch.load(\"normalization_cache/rgb_std.pth\").unsqueeze(0).unsqueeze(-1).unsqueeze(-1).to(DEVICE)\n",
    "\n",
    "log(\"Mean shape: \", rgb_mean)\n",
    "log(\"Sigma shape? \", rgb_sigma)\n",
    "\n",
    "model = MappingUnet()\n",
    "#print(model)\n",
    "\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "log(\"Trainable parameters:\", trainable_params)\n",
    "\n",
    "num_epochs = 10\n",
    "batch_size = 8\n",
    "\n",
    "model = model.train().to(DEVICE)\n",
    "\n",
    "dataloader = DataLoader(dataset=dataset, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "beta_schedule = BetaScheduler(len(dataloader))\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4, weight_decay=1e-4)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, num_epochs*len(dataloader), eta_min=1e-6)\n",
    "\n",
    "\n",
    "aug = transforms.Compose([\n",
    "    transforms.ColorJitter(brightness=0.1, saturation=0.1, hue=1e-6),\n",
    "])\n",
    "\n",
    "betas = []\n",
    "for i in range(num_epochs):\n",
    "    print(\"-------------------- Epoch\", i+1, \"/\", num_epochs, \" --------------------\")\n",
    "    beta_schedule.reset()\n",
    "    for batch, (im_true, _, _) in enumerate(dataloader):\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        im_true = im_true.to(DEVICE)\n",
    "        im_rand = aug(im_true.to(DEVICE).byte()).float()\n",
    "        im_rand = (im_rand-rgb_mean)/rgb_sigma\n",
    "        im_true = (im_true-rgb_mean)/rgb_sigma\n",
    "\n",
    "\n",
    "        #im_rand = im_rand.to(DEVICE)\n",
    "        #im_rand = (im_rand-rgb_mean)/rgb_sigma\n",
    "\n",
    "        im_pred, latent, latent_mu, latent_logvar = model(im_true)\n",
    "\n",
    "        #loss = F.mse_loss(im_pred, im_rand)\n",
    "        loss, kl_loss, recon_loss = VAE_loss(im_true, im_pred, latent_mu, latent_logvar, beta=beta_schedule.step())\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "        #print(\"Iteration: \", batch, \"/\", len(dataloader), \"\\t\\t Loss: \", loss.item(), \"\\t LR: \", scheduler.get_last_lr())\n",
    "        print(\"Iteration: \", batch, \"/\", len(dataloader), \"\\t\\t Loss: \", loss.item(), \"\\tKLD loss: \", kl_loss.item(), \"\\tReconstruction loss: \", recon_loss.item(), \"\\t LR: \", scheduler.get_last_lr())\n",
    "    \n",
    "    model_name = \"localization/MappingUnet_last_0_0.pth\"\n",
    "    log(\"Saving model as \", model_name)\n",
    "    torch.save(model.state_dict(), model_name)\n",
    "\n",
    "torch.save(torch.tensor(betas), \"betas.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from localization.localization import MappingUnet\n",
    "import torch\n",
    "\n",
    "model = MappingUnet()\n",
    "rgb_mean = torch.load(\"normalization_cache/rgb_mean.pth\").unsqueeze(0).unsqueeze(-1).unsqueeze(-1).to(DEVICE)\n",
    "rgb_sigma = torch.load(\"normalization_cache/rgb_std.pth\").unsqueeze(0).unsqueeze(-1).unsqueeze(-1).to(DEVICE)\n",
    "\n",
    "model.load_state_dict(torch.load(\"localization/MappingUnet_last_0_0.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IndexRegressor = nn.Sequential(\n",
    "    nn.Linear(in_features=1024, out_features=256),\n",
    "    nn.PReLU(),\n",
    "    nn.Dropout(0.2),\n",
    "    nn.Linear(in_features=256, out_features=64),\n",
    "    nn.PReLU(),\n",
    "    nn.Dropout(0.2),\n",
    "    nn.Linear(in_features=64, out_features=1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from localization.localization_dataset import KittiLocalizationDataset\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "from helpers import log\n",
    "import numpy as np\n",
    "\n",
    "DEVICE = \"cuda\"\n",
    "\n",
    "mpl.rcParams['figure.dpi'] = 150\n",
    "\n",
    "latent_space_vectors = []\n",
    "model.to(DEVICE).eval()\n",
    "\n",
    "DATA_PATH = None # TODO Change to config file data read\n",
    "dataset = KittiLocalizationDataset(data_path=DATA_PATH, sequence=\"00\", simplify=True, simplification_rate=8)\n",
    "log(\"Dataset shape: \", len(dataset))\n",
    "\n",
    "random_index = int(torch.randint(low=0, high=len(dataset), size=(1, 1)).squeeze())\n",
    "log(\"Index: \", random_index)\n",
    "\n",
    "with torch.no_grad():\n",
    "    \n",
    "    true_im, _, _ = dataset[random_index]\n",
    "    im_normalized = (true_im.to(\"cuda\")-rgb_mean)/rgb_sigma\n",
    "    prediction, test_latent, test_mu, _ = model(im_normalized)\n",
    "    \n",
    "    DATA_PATH = None # TODO Change to config file data read\n",
    "    dataset = KittiLocalizationDataset(data_path=DATA_PATH, sequence=\"00\", simplify=True, simplification_rate=7)\n",
    "    log(\"Dataset shape: \", len(dataset))\n",
    "\n",
    "    for i in range(len(dataset)):\n",
    "        test_im, _, _ = dataset[i]\n",
    "        im_normalized = (test_im.to(\"cuda\")-rgb_mean)/rgb_sigma\n",
    "        im_pred, latent, mu, _ = model(im_normalized)\n",
    "        #latent_space_vectors.append(latent)\n",
    "        latent_space_vectors.append(mu)\n",
    "\n",
    "        \n",
    "\n",
    "    distances = []\n",
    "    for i in range(len(latent_space_vectors)):\n",
    "        dist = (latent_space_vectors[i]-test_mu)\n",
    "        dist = torch.norm(dist, p=2).detach().to('cpu')\n",
    "        distances.append(dist)\n",
    "\n",
    "distances = torch.stack(distances, dim=0)\n",
    "log(\"Distances shape\", distances.shape)\n",
    "\n",
    "plt.plot(distances.numpy())\n",
    "plt.xlabel(\"Index of latent space vector\")\n",
    "plt.ylabel(\"Distance from sample\")\n",
    "plt.show()\n",
    "\n",
    "max_dist = torch.max(distances)\n",
    "bins = 1000\n",
    "[hist, bins] = np.histogram(distances.numpy(), bins=bins)\n",
    "\n",
    "# ---------\n",
    "# Histogram\n",
    "# ---------\n",
    "plt.bar(bins[:-1], hist)\n",
    "plt.xlabel(\"Distance from sample\")\n",
    "plt.ylabel(\"Count of elements\")\n",
    "plt.show()\n",
    "\n",
    "# Predicted index\n",
    "pred_index = torch.argmin(distances)\n",
    "log(\"Pred index\", pred_index)\n",
    "\n",
    "def prepare_im(im):\n",
    "    return im.detach().byte().squeeze().permute(1, 2, 0).numpy()\n",
    "\n",
    "pred_im, _, _ = dataset[int(pred_index.squeeze())]\n",
    "\n",
    "plt.imshow(prepare_im(true_im))\n",
    "plt.show()\n",
    "plt.imshow(prepare_im(pred_im))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8ac8d4502ca59ae65a69058a7f49955eae7024f30b41bc88446bb7ebbedcf534"
  },
  "kernelspec": {
   "display_name": "Python 3.6.9 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
