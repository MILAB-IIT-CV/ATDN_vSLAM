{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from localization_dataset import KittiLlocalizationDataset\n",
    "from localization import LocalizationNet, PoseRegressor\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "\n",
    "from helpers import log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = None # TODO Change to config file data read\n",
    "\n",
    "dataset = KittiLlocalizationDataset(DATA_PATH, \"00\")\n",
    "loader = DataLoader(dataset, batch_size=16, shuffle=True, drop_last=True)\n",
    "\n",
    "autoencoder_model = nn.DataParallel(LocalizationNet()).to('cuda')\n",
    "autoencoder_model.train()\n",
    "autoencoder_model.load_state_dict(torch.load(\"MapAutoEncoder.pth\"))\n",
    "trainable_params = sum(p.numel() for p in autoencoder_model.parameters() if p.requires_grad)\n",
    "log(\"Trainable parameters:\", trainable_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def autoencoder_loss(true, pred):\n",
    "\n",
    "    #rot, tr = true\n",
    "    diff = (true-pred)**2\n",
    "    loss = diff.mean()\n",
    "\n",
    "    return loss*0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, loader, optimizer, scheduler, log_vals=[]):\n",
    "    for batch, blob in enumerate(loader):\n",
    "        img1, rot_true, tr_true = blob\n",
    "\n",
    "        img1 = torch.squeeze(img1).to('cuda')\n",
    "        optimizer.zero_grad()\n",
    "        transform_pred = model(img1)\n",
    "        loss = autoencoder_loss(img1, transform_pred)\n",
    "        \n",
    "        log_vals.append(loss.item())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        \n",
    "\n",
    "        current = batch\n",
    "        print(\"\", end='\\r')\n",
    "        print(\"Iteration: %d / %d \\t|\\t Loss: %5f\" % (current, len(loader), loss.item()), end='\\n')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "epochs = 2\n",
    "log_vals = []\n",
    "optimizer = optim.AdamW(autoencoder_model.parameters(), lr=1e-3, weight_decay=0.01)\n",
    "#optimizer = optim.Adam(model.parameters(), lr=4*1e-3)\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, epochs*len(loader), eta_min=1e-5)\n",
    "\n",
    "autoencoder_model.train()\n",
    "print(\"============== \", \"Training\", \" ==============\\n\")\n",
    "for epoch in range(epochs):\n",
    "    print(\"---------- \", \"Epoch \", epoch, \" ----------\\n\")\n",
    "    train(autoencoder_model, loader, optimizer, scheduler, log_vals)\n",
    "    plt.plot(log_vals)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autoencoder test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(autoencoder_model.state_dict(), 'MapAutoEncoder.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder_model.eval()\n",
    "modul = autoencoder_model.module\n",
    "img1, rot, tr = dataset[2000]\n",
    "pred = modul(img1)\n",
    "code = modul.get_code(img1)\n",
    "img1 = torch.squeeze(img1).cpu().permute((1,  2, 0)).int().numpy()\n",
    "\n",
    "plt.imshow(img1)\n",
    "plt.show()\n",
    "pred = torch.squeeze(pred).cpu().permute((1,  2, 0)).int().numpy()\n",
    "plt.imshow(pred)\n",
    "plt.show()\n",
    "plt.imshow((img1-pred)**2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "img1, rot, tr = dataset[96]\n",
    "img2, rot, tr = dataset[98]\n",
    "plt.imsave(\"True0.png\", torch.squeeze(img1).cpu().permute((1,  2, 0)).int().numpy().astype(np.uint8))\n",
    "plt.imsave(\"True1.png\", torch.squeeze(img2).cpu().permute((1,  2, 0)).int().numpy().astype(np.uint8))\n",
    "\n",
    "\n",
    "code1 = autoencoder_model.module.get_code(img1)\n",
    "\n",
    "pred1 = autoencoder_model.module.generate_from_code(code1)\n",
    "pred1 = torch.squeeze(pred1).cpu().permute((1,  2, 0)).int().numpy()\n",
    "\n",
    "code2 = autoencoder_model.module.get_code(img2)\n",
    "pred2 = autoencoder_model.module.generate_from_code(code2)\n",
    "pred2 = torch.squeeze(pred2).cpu().permute((1,  2, 0)).int().numpy()\n",
    "\n",
    "plt.imshow(pred1)\n",
    "plt.show()\n",
    "print()\n",
    "print()\n",
    "print()\n",
    "print()\n",
    "\n",
    "diff = (code2-code1)/16\n",
    "code = code1\n",
    "for i in range(16):\n",
    "    code = code + diff\n",
    "    pred = autoencoder_model.module.generate_from_code(code)\n",
    "    pred = torch.squeeze(pred).cpu().permute((1,  2, 0)).int().numpy()\n",
    "    plt.imsave(str(i)+'.png', pred.astype(np.uint8))\n",
    "    plt.imshow(pred)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "print()\n",
    "print()\n",
    "print()\n",
    "print()\n",
    "plt.imshow(pred2)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "localization_model = nn.DataParallel(PoseRegressor()).to('cuda')\n",
    "trainable_params = sum(p.numel() for p in localization_model.parameters() if p.requires_grad)\n",
    "log(\"Trainable parameters:\", trainable_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def localization_loss(rot_true, tr_true, rot_pred, tr_pred):\n",
    "    diff_rot = rot_true-rot_pred\n",
    "    diff_tr = tr_true-tr_pred\n",
    "\n",
    "    loss = (diff_rot**2).sum(-1).mean() + 100*(diff_tr**2).sum(-1).mean()\n",
    "    return loss\n",
    "\n",
    "def train(model, autoencoder, loader, optimizer, scheduler, log_vals=[]):\n",
    "    for batch, blob in enumerate(loader):\n",
    "        img1, rot_true, tr_true = blob\n",
    "        \n",
    "        img1 = torch.squeeze(img1).to('cuda')\n",
    "        rot_true = rot_true.to('cuda')\n",
    "        tr_true = tr_true.to('cuda')\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        code = autoencoder.module.get_code(img1)\n",
    "        rot_pred, tr_pred = model(code)\n",
    "        \n",
    "        loss = localization_loss(rot_true, tr_true, rot_pred, tr_pred)\n",
    "        \n",
    "        log_vals.append(loss.item())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        \n",
    "\n",
    "        current = batch\n",
    "        print(\"\", end='\\r')\n",
    "        print(\"Iteration: %d / %d \\t|\\t Loss: %5f\" % (current, len(loader), loss.item()), end='\\n')\n",
    "\n",
    "\n",
    "\n",
    "localization_model.train()\n",
    "autoencoder_model.eval()\n",
    "epochs = 2\n",
    "log_vals = []\n",
    "optimizer = optim.AdamW(autoencoder_model.parameters(), lr=1e-5, weight_decay=0.001)\n",
    "#optimizer = optim.Adam(model.parameters(), lr=4*1e-3)\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, epochs*len(loader), eta_min=1e-5)\n",
    "\n",
    "autoencoder_model.train()\n",
    "print(\"============== \", \"Training\", \" ==============\\n\")\n",
    "for epoch in range(epochs):\n",
    "    print(\"---------- \", \"Epoch \", epoch, \" ----------\\n\")\n",
    "    train(localization_model, autoencoder_model, loader, optimizer, scheduler, log_vals)\n",
    "    plt.plot(log_vals)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(localization_model.state_dict(), 'LocalizationNet.pth')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "fd69f43f58546b570e94fd7eba7b65e6bcc7a5bbc4eab0408017d18902915d69"
  },
  "kernelspec": {
   "display_name": "Python 3.7.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
