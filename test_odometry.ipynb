{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CLVO Netrwork development"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PyTorch imports\n",
    "import torch\n",
    "\n",
    "# Other external package imports\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Project module imports\n",
    "from odometry.vo_datasets import FlowKittiDataset\n",
    "from odometry.clvo import CLVO\n",
    "from utils.helpers import log, transform\n",
    "from utils.arguments import Arguments\n",
    "from utils.normalization import FlowStandardization\n",
    "\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams['figure.dpi'] = 100\n",
    "\n",
    "# Instantiating arguments object for optical flow module\n",
    "args = Arguments.get_arguments()\n",
    "\n",
    "# Instantiating dataset and dataloader\n",
    "batch_size = 16\n",
    "sequence_length = 1\n",
    "dataset = FlowKittiDataset(args.data_path, [\"00\"], augment=False, sequence_length=1)\n",
    "\n",
    "model = CLVO().to(args.device)\n",
    "model.load_state_dict(torch.load(\"checkpoints/clvo_generalization4_1.pth\", map_location=args.device))\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "log(\"Trainable parameters:\", trainable_params)\n",
    "\n",
    "normalization =  FlowStandardization().eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running inference on 00 and collecting output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    model.to(args.device)\n",
    "    model.eval()\n",
    "\n",
    "    translations = []\n",
    "    rotations = []\n",
    "    #resize = Resize((376, 1248))\n",
    "    use_model = True\n",
    "\n",
    "    count = 0\n",
    "    for i in range(0, len(dataset), 1):\n",
    "        flow, rot, tr = dataset[i]\n",
    "        if use_model:\n",
    "            flow = normalization(flow.unsqueeze(0).to(args.device))\n",
    "\n",
    "            rot, tr = model(flow)\n",
    "        rot = rot.detach()\n",
    "        tr = tr.detach()\n",
    "        \n",
    "        rotations.append(rot)        \n",
    "        translations.append(tr)\n",
    "        \n",
    "        #for j in range(len(rot)):\n",
    "        #    translation = tr[j].squeeze()\n",
    "        #    rotation = rot[j].squeeze()\n",
    "\n",
    "            #translations.append(translation)\n",
    "            #rotations.append(rotation)\n",
    "\n",
    "        print('    ', end='\\r')\n",
    "        print(count, end='')\n",
    "        count = count+1\n",
    "\n",
    "    print()\n",
    "    log(\"Data loading Done!\")\n",
    "    log(\"Rot length: \", len(rotations))\n",
    "    log(\"Tr length: \", len(translations))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rel->Abs coordinate conversion and plotting results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "homogenous = []\n",
    "\n",
    "instance_num = len(rotations)\n",
    "for i in range(instance_num):\n",
    "    homogenous.append(transform(rotations[i].squeeze(), translations[i].squeeze()))\n",
    "\n",
    "global_scale = []\n",
    "global_scale.append(homogenous[0])\n",
    "for i in range(1, instance_num):\n",
    "    global_scale.append(torch.matmul(global_scale[i-1], homogenous[i]))\n",
    "    \n",
    "global_scale = torch.stack(global_scale, dim=0)\n",
    "global_pos = global_scale[:, :3, -1]\n",
    "\n",
    "\n",
    "# Plotting results\n",
    "numpy_poses = []\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams['figure.dpi'] = 100\n",
    "\n",
    "for i in range(len(global_scale)):\n",
    "    numpy_poses.append((np.array(global_scale[i][:3, :].view(12).numpy())))\n",
    "numpy_poses = np.stack(numpy_poses, axis=0)\n",
    "\n",
    "np.savetxt(\"results.txt\", numpy_poses)\n",
    "reloaded_poses = np.loadtxt(\"results.txt\")\n",
    "\n",
    "X = np.array([p[3] for p in reloaded_poses])\n",
    "Z = np.array([p[-1] for p in reloaded_poses])\n",
    "\n",
    "plt.plot(X, Z)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison with Ground Truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = args.data_path + \"/dataset/poses/00.txt\"\n",
    "true_pos = np.loadtxt(DATA_PATH)\n",
    "\n",
    "X_gt, Y_gt, Z_gt = true_pos[:, 3], true_pos[:, 7], true_pos[:, 11]\n",
    "X, Y, Z = global_pos[:, 0], global_pos[:, 1], global_pos[:, 2]\n",
    "\n",
    "plt.plot(X, Z, label=\"pred\")\n",
    "plt.plot(X_gt, Z_gt, label=\"gt\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.plot(X, label=\"pred\")\n",
    "plt.plot(X_gt, label=\"gt\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.plot(Y, label=\"pred\")\n",
    "plt.plot(Y_gt, label=\"gt\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.plot(Z, label=\"pred\")\n",
    "plt.plot(Z_gt, label=\"gt\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "mpl.rcParams['figure.dpi'] = 100\n",
    "\n",
    "X, Y, Z = global_pos[:, 0], global_pos[:, 1], global_pos[:, 2]\n",
    "\n",
    "plt.plot(X, Z)\n",
    "plt.show()\n",
    "plt.plot(X)\n",
    "plt.show()\n",
    "plt.plot(Y)\n",
    "plt.show()\n",
    "plt.plot(Z)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from odometry.vo_datasets import KittiOdometryDataset\n",
    "from utils.arguments import Arguments\n",
    "from GMA.core.utils import flow_viz\n",
    "import torch\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams['figure.dpi'] = 150\n",
    "\n",
    "dataset = KittiOdometryDataset(args.data_path, \"00\", precomputed_flow=True, sequence_length=1)\n",
    "\n",
    "def viz(flo):\n",
    "    flo = flo[0].permute(1, 2, 0).cpu().numpy()\n",
    "    # map flow to rgb image\n",
    "    flo = flow_viz.flow_to_image(flo)\n",
    "    return flo\n",
    "    \n",
    "\n",
    "for i in range(4):\n",
    "    im1, im2, flow, rot, tr = dataset[i]\n",
    "    flo_im = viz(flow[0].squeeze)\n",
    "    plt.imshow(flo_im)\n",
    "    plt.show()\n",
    "    #DATA_PATH = None # TODO Define save path\n",
    "    #plt.imsave(DATA_PATH + str(i) + \".png\", flo_im)\n",
    "    #print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8d9c4e0ef343f48ddb8b3296df994136284bc2ec1cb5bd3ca0b75344a28b97fb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
