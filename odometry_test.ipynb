{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CLVO Netrwork development"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PyTorch imports\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.transforms import Resize\n",
    "\n",
    "# Other external package imports\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Project module imports\n",
    "from odometry.vo_datasets import KittiOdometryDataset\n",
    "from odometry.clvo import CLVO\n",
    "from helpers import log, euler2matrix\n",
    "from arguments import Arguments\n",
    "\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams['figure.dpi'] = 100\n",
    "\n",
    "# Instantiating arguments object for optical flow module\n",
    "args = Arguments.get_arguments()\n",
    "\n",
    "# Instantiating dataset and dataloader\n",
    "batch_size = 16\n",
    "sequence_length = 1\n",
    "dataset = KittiOdometryDataset(args.data_path, \"00\", precomputed_flow=True, sequence_length=sequence_length)\n",
    "loader = DataLoader(dataset=dataset, batch_size=batch_size, shuffle=True, drop_last=True, num_workers=2, pin_memory=True)\n",
    "\n",
    "\n",
    "im_mean = torch.load(\"normalization_cache/rgb_mean.pth\").unsqueeze(-1).unsqueeze(-1).unsqueeze(0).to(args.device)\n",
    "im_std = torch.load(\"normalization_cache/rgb_std.pth\").unsqueeze(-1).unsqueeze(-1).unsqueeze(0).to(args.device)\n",
    "flows_mean = torch.load(\"normalization_cache/flow_mean.pth\").unsqueeze(-1).unsqueeze(-1).unsqueeze(0).to(args.device)\n",
    "flows_std = torch.load(\"normalization_cache/flow_std.pth\").unsqueeze(-1).unsqueeze(-1).unsqueeze(0).to(args.device)\n",
    "\n",
    "\n",
    "model = CLVO(args, precomputed_flows=True, in_channels=8).to(args.device)\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "resize = Resize(75)\n",
    "\n",
    "log(\"Trainable parameters:\", trainable_params)\n",
    "\n",
    "model.load_state_dict(torch.load(\"odometry/clvo_final_adam_3.pth\", map_location=args.device))\n",
    "print(\"RGBs mean: \", im_mean.squeeze())\n",
    "print(\"RGBs Std: \", im_std.squeeze())\n",
    "\n",
    "print(\"Flows mean: \", flows_mean.squeeze())\n",
    "print(\"Flows std: \", flows_std.squeeze())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visual evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = KittiOdometryDataset(args.data_path, \"00\", precomputed_flow=True, sequence_length=1)\n",
    "with torch.no_grad():\n",
    "    model.to(args.device)\n",
    "    model.eval()\n",
    "\n",
    "    translations = []\n",
    "    rotations = []\n",
    "    \n",
    "    use_model = True\n",
    "\n",
    "    count = 0\n",
    "    for i in range(0, len(dataset), 1):\n",
    "        im1, im2, flow, rot, tr = dataset[i]\n",
    "\n",
    "        if use_model:\n",
    "            im1 = im1.squeeze().to(args.device)\n",
    "            im1 = (im1-im_mean)/im_std\n",
    "\n",
    "            im2 = im2.squeeze().to(args.device)\n",
    "            im2 = (im2-im_mean)/im_std\n",
    "\n",
    "            flow = flow.squeeze().to(args.device)\n",
    "            flow = (flow-flows_mean)/flows_std\n",
    "            input_data = torch.cat([flow, im1, im2], dim=1)\n",
    "            #print(input_data.shape)\n",
    "            #input_data = torch.cat([flow, im1], dim=1)\n",
    "\n",
    "            rot, tr = model(input_data)\n",
    "        rot = rot.detach()\n",
    "        tr = tr.detach()\n",
    "        \n",
    "        rotations.append(rot)        \n",
    "        translations.append(tr)\n",
    "        \n",
    "        #for j in range(len(rot)):\n",
    "        #    translation = tr[j].squeeze()\n",
    "        #    rotation = rot[j].squeeze()\n",
    "\n",
    "            #translations.append(translation)\n",
    "            #rotations.append(rotation)\n",
    "\n",
    "        print('    ', end='\\r')\n",
    "        print(count, end='')\n",
    "        count = count+1\n",
    "\n",
    "    print()\n",
    "    log(\"Data loading Done!\")\n",
    "    log(\"Rot length: \", len(rotations))\n",
    "    log(\"Tr length: \", len(translations))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform(rot, tr):\n",
    "    rot = euler2matrix(rot, device=\"cpu\")\n",
    "    mat = torch.cat([rot, tr.unsqueeze(1).to('cpu')], dim=1)\n",
    "    mat = torch.cat([mat, torch.tensor([[0, 0, 0, 1]])], dim=0)\n",
    "\n",
    "    return mat\n",
    "\n",
    "homogenous = []\n",
    "\n",
    "instance_num = len(rotations)\n",
    "for i in range(instance_num):\n",
    "    homogenous.append(transform(rotations[i], translations[i]))\n",
    "\n",
    "global_scale = []\n",
    "global_scale.append(homogenous[0])\n",
    "for i in range(1, instance_num):\n",
    "    global_scale.append(torch.matmul(global_scale[i-1], homogenous[i]))\n",
    "    \n",
    "global_scale = torch.stack(global_scale, dim=0)\n",
    "global_pos = global_scale[:, :3, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numpy_poses = []\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams['figure.dpi'] = 100\n",
    "\n",
    "for i in range(len(global_scale)):\n",
    "    numpy_poses.append((np.array(torch.cat([global_scale[i][0, :], global_scale[i][1, :], global_scale[i][2, :]], dim=0).numpy())))\n",
    "numpy_poses = np.stack(numpy_poses, axis=0)\n",
    "\n",
    "np.savetxt(\"results.txt\", numpy_poses)\n",
    "reloaded_poses = np.loadtxt(\"results.txt\")\n",
    "\n",
    "X = np.array([p[3] for p in reloaded_poses])\n",
    "Z = np.array([p[-1] for p in reloaded_poses])\n",
    "\n",
    "\n",
    "plt.plot(X, Z)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = args.data_path + \"/dataset/poses/00.txt\"\n",
    "true_pos = np.loadtxt(DATA_PATH)\n",
    "\n",
    "X_gt, Y_gt, Z_gt = true_pos[:, 3], true_pos[:, 7], true_pos[:, 11]\n",
    "X, Y, Z = global_pos[:, 0], global_pos[:, 1], global_pos[:, 2]\n",
    "\n",
    "plt.plot(X, Z, label=\"pred\")\n",
    "plt.plot(X_gt, Z_gt, label=\"gt\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.plot(X, label=\"pred\")\n",
    "plt.plot(X_gt, label=\"gt\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.plot(Y, label=\"pred\")\n",
    "plt.plot(Y_gt, label=\"gt\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.plot(Z, label=\"pred\")\n",
    "plt.plot(Z_gt, label=\"gt\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "mpl.rcParams['figure.dpi'] = 100\n",
    "\n",
    "X, Y, Z = global_pos[:, 0], global_pos[:, 1], global_pos[:, 2]\n",
    "\n",
    "plt.plot(X, Z)\n",
    "plt.show()\n",
    "plt.plot(X)\n",
    "plt.show()\n",
    "plt.plot(Y)\n",
    "plt.show()\n",
    "plt.plot(Z)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from odometry.vo_datasets import KittiOdometryDataset\n",
    "from arguments import Arguments\n",
    "from GMA.core.utils import flow_viz\n",
    "import torch\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams['figure.dpi'] = 150\n",
    "\n",
    "dataset = KittiOdometryDataset(args.data_path, \"00\", precomputed_flow=True, sequence_length=1)\n",
    "\n",
    "def viz(flo):\n",
    "    flo = flo[0].permute(1, 2, 0).cpu().numpy()\n",
    "    # map flow to rgb image\n",
    "    flo = flow_viz.flow_to_image(flo)\n",
    "    return flo\n",
    "    \n",
    "\n",
    "for i in range(4):\n",
    "    im1, im2, flow, rot, tr = dataset[i]\n",
    "    flo_im = viz(flow[0].squeeze)\n",
    "    plt.imshow(flo_im)\n",
    "    plt.show()\n",
    "    #DATA_PATH = None # TODO Define save path\n",
    "    #plt.imsave(DATA_PATH + str(i) + \".png\", flo_im)\n",
    "    #print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8d9c4e0ef343f48ddb8b3296df994136284bc2ec1cb5bd3ca0b75344a28b97fb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
