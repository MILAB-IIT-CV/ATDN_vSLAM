{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Localozation net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from localization.localization import MappingVAE, MappingUnet\n",
    "from helpers import log, Arguments\n",
    "from localization.localization_dataset import KittiLocalizationDataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "args = Arguments.get_arguments()\n",
    "dataset = KittiLocalizationDataset(data_path=args.data_path, sequence=\"00\", simplify=True, simplification_rate=10)\n",
    "\n",
    "rgb_mean = torch.load(\"normalization_cache/rgb_mean.pth\").unsqueeze(0).unsqueeze(-1).unsqueeze(-1).to(args.device)\n",
    "rgb_sigma = torch.load(\"normalization_cache/rgb_std.pth\").unsqueeze(0).unsqueeze(-1).unsqueeze(-1).to(args.device)\n",
    "\n",
    "log(\"Mean: \", rgb_mean.squeeze())\n",
    "log(\"Sigma: \", rgb_sigma.squeeze())\n",
    "\n",
    "#model = MappingVAE()\n",
    "model = MappingUnet()\n",
    "#model.load_state_dict(torch.load(\"localization/MappingVAE_last_0_0.pth\"))\n",
    "#model = model.to(DEVICE)\n",
    "\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "log(\"Trainable parameters:\", trainable_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers import BetaScheduler\n",
    "from torchvision import transforms\n",
    "from localization.localization_losses import VAE_loss\n",
    "from torchvision.transforms import Resize\n",
    "import torch.nn.functional as F\n",
    "\n",
    "num_epochs = 10\n",
    "batch_size = 8\n",
    "\n",
    "model = model.train().to(args.device)\n",
    "#resizer = Resize((128, 384))\n",
    "dataloader = DataLoader(dataset=dataset, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "\n",
    "#optimizer = torch.optim.AdamW(model.parameters(), lr=1e-3, weight_decay=1e-5)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, num_epochs*len(dataloader), eta_min=1e-5)\n",
    "beta_schedule = BetaScheduler(len(dataloader))\n",
    "\n",
    "aug = transforms.Compose([\n",
    "    transforms.ColorJitter(brightness=0.1, saturation=0.1, hue=1e-4),\n",
    "])\n",
    "\n",
    "betas = []\n",
    "for i in range(num_epochs):\n",
    "    print(\"-------------------- Epoch\", i+1, \"/\", num_epochs, \" --------------------\")\n",
    "    \n",
    "    beta_schedule.reset()\n",
    "    for batch, (im, _, _) in enumerate(dataloader):\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        im = im.to(args.device)\n",
    "        im_normalized = (im-rgb_mean)/rgb_sigma\n",
    "        #im_normalized = im/255\n",
    "        aug_normalized = (aug(im)-rgb_mean)/rgb_sigma\n",
    "\n",
    "        #mu, logvar, latent, im_pred = model(im_normalized, VAE=True)\n",
    "        mu, logvar, latent, im_pred = model(im_normalized)\n",
    "\n",
    "        #loss, kl_loss, reconstruction_loss = VAE_loss(im_normalized, im_pred, mu.flatten(1), logvar.flatten(1), beta=beta_schedule.step())\n",
    "        loss1 = F.mse_loss(im_pred, im_normalized)\n",
    "        loss2 = torch.abs(torch.norm(torch.exp(0.5*logvar), p=2)-1.0)        \n",
    "        loss = loss1 + loss2\n",
    "        #reconstruction_loss = None\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "        #print(\"Loss: \", loss.item(), \"\\t LR: \", scheduler.get_last_lr())\n",
    "        print(\"Iteration: \", batch, \"/\", len(dataloader), \"\\t\\t Loss: \", loss.item(), \"\\t LR: \", scheduler.get_last_lr())\n",
    "        #print(\"Iteration: \", batch, \"/\", len(dataloader), \"\\t\\t Loss: \", loss.item(), \"\\tKLD loss: \", kl_loss.item(), \"\\tReconstruction loss: \", reconstruction_loss.item(), \"\\t LR: \", scheduler.get_last_lr())\n",
    "    \n",
    "    model_name = \"localization/MappingVAE_last_0_0.pth\"\n",
    "    log(\"Saving model as \", model_name)\n",
    "    torch.save(model.state_dict(), model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reconstruction check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "\n",
    "mpl.rcParams['figure.dpi'] = 120\n",
    "\n",
    "im, _, _ = dataset[100]\n",
    "plt.imshow(im.permute(1, 2, 0).byte().cpu().detach().numpy())\n",
    "plt.show()\n",
    "\n",
    "im_normalized = (im.to(args.device)-rgb_mean)/rgb_sigma\n",
    "#mu, logvar, latent, im_pred = model(im_normalized, VAE=True)\n",
    "mu, logvar, latent, im_pred = model(im_normalized)\n",
    "\n",
    "pred_back = (im_pred*rgb_sigma)+rgb_mean\n",
    "pred_back = torch.minimum(pred_back, torch.tensor(255.0))\n",
    "pred_back = torch.maximum(pred_back, torch.tensor(0.0))\n",
    "pred_back = pred_back.cpu().squeeze().byte().permute(1, 2, 0).numpy()\n",
    "plt.imshow(pred_back)\n",
    "plt.show()\n",
    "plt.imsave(\"Unet_sigmaloss.png\", pred_back)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Relocalization capability testing code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "from helpers import log\n",
    "import numpy as np\n",
    "\n",
    "latent_space_vectors = []\n",
    "model.to(args.device).eval()\n",
    "\n",
    "simplification_rate_1=7\n",
    "simplification_rate_2=9\n",
    "\n",
    "dataset = KittiLocalizationDataset(data_path=args.data_path, sequence=\"00\", simplify=True, simplification_rate=simplification_rate_1)\n",
    "#log(\"Dataset shape: \", len(dataset))\n",
    "\n",
    "random_index = 74 #int(torch.randint(low=0, high=len(dataset), size=(1, 1)).squeeze())\n",
    "log(\"True index: \", random_index*simplification_rate_1)\n",
    "\n",
    "with torch.no_grad():\n",
    "    \n",
    "    true_im, _, _ = dataset[random_index]\n",
    "    im_normalized = (true_im.to(args.device)-rgb_mean)/rgb_sigma\n",
    "    #true_mu, logvar, true_latent, prediction = model(im_normalized, VAE=True)\n",
    "    true_mu, logvar, true_latent, prediction = model(im_normalized)\n",
    "    #test_mu = test_latent\n",
    "    #log(\"Test mu shape: \", test_mu.shape)\n",
    "    \n",
    "    dataset = KittiLocalizationDataset(data_path=args.data_path, sequence=\"00\", simplify=True, simplification_rate=simplification_rate_2)\n",
    "    #log(\"Dataset shape: \", len(dataset))\n",
    "\n",
    "    for i in range(len(dataset)):\n",
    "        test_im, _, _ = dataset[i]\n",
    "        im_normalized = (test_im.to(args.device)-rgb_mean)/rgb_sigma\n",
    "        #mu, logvar, latent, im_pred = model(im_normalized, VAE=True)\n",
    "        mu, logvar, latent, im_pred = model(im_normalized)\n",
    "        latent_space_vectors.append(mu)\n",
    "        #latent_space_vectors.append(mu)\n",
    "\n",
    "    distances = []\n",
    "    for i in range(len(latent_space_vectors)):\n",
    "        dist = (latent_space_vectors[i]-true_mu)\n",
    "        dist = torch.norm(dist, p=2).detach().to('cpu')\n",
    "        #print(dist)\n",
    "        distances.append(dist)\n",
    "\n",
    "distances = torch.stack(distances, dim=0)\n",
    "#log(\"Distances shape\", distances.shape)\n",
    "\n",
    "bins = 1000\n",
    "[hist, bin_edges] = np.histogram(distances, bins=bins)\n",
    "\n",
    "# ---------\n",
    "# Histogram\n",
    "# ---------\n",
    "\n",
    "plt.bar(bin_edges[:-1], hist)\n",
    "plt.xlabel(\"Distance from sample\")\n",
    "plt.ylabel(\"Count of elements\")\n",
    "plt.show()\n",
    "\n",
    "# Predicted index\n",
    "distances_mean = distances.mean()\n",
    "pred_index = torch.argmin(distances)\n",
    "\n",
    "log(\"Pred index\", pred_index*simplification_rate_2)\n",
    "\n",
    "plt.plot(distances.numpy())\n",
    "plt.xlabel(\"Index of latent space vector\")\n",
    "plt.ylabel(\"Distance from sample\")\n",
    "plt.show()\n",
    "\n",
    "mean_distance1 = (distances[pred_index]-distances_mean).abs()\n",
    "log(\"Mean: \", distances_mean)\n",
    "log(\"Pred-mean:\",  mean_distance1)\n",
    "\n",
    "def prepare_im(im):\n",
    "    return im.detach().byte().squeeze().permute(1, 2, 0).numpy()\n",
    "\n",
    "\n",
    "pred_im, _, _ = dataset[int(pred_index.squeeze())]\n",
    "\n",
    "plt.imshow(prepare_im(true_im))\n",
    "plt.show()\n",
    "plt.imshow(prepare_im(pred_im))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8d9c4e0ef343f48ddb8b3296df994136284bc2ec1cb5bd3ca0b75344a28b97fb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
